{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Food Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict why some batches of their dog food are spoiling much quicker than intended for a Dog Food company! Unfortunately this Dog Food company hasn't upgraded to the latest machinery, meaning that the amounts of the five preservative chemicals they are using can vary a lot, but which is the chemical that has the strongest effect? The dog food company first mixes up a batch of preservative that contains 4 different preservative chemicals (A,B,C,D) and then is completed with a \"filler\" chemical. The food scientists beelive one of the A,B,C, or D preservatives is causing the problem, but need your help to figure out which one! Using Machine Learning with Random Forest Tree model to find out which parameter had the most predicitive power, thus finding out which chemical causes the early spoiling!\n",
    "\n",
    "\n",
    "* **Pres_A**: Percentage of preservative A in the mix\n",
    "* **Pres_B**: Percentage of preservative B in the mix\n",
    "* **Pres_C**: Percentage of preservative C in the mix\n",
    "* **Pres_D**: Percentage of preservative D in the mix\n",
    "* **Spoiled**: Label indicating whether or not the dog food batch was spoiled.\n",
    "___\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pyspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and create a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('dog_food').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Spark to read the Dog Food data set\n",
    "data = spark.read.csv('dog_food.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+---+-------+\n",
      "|  A|  B|   C|  D|Spoiled|\n",
      "+---+---+----+---+-------+\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "|  5|  6|12.0|  7|    1.0|\n",
      "|  6|  2|13.0|  6|    1.0|\n",
      "|  4|  2|12.0|  1|    1.0|\n",
      "+---+---+----+---+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the first few rows of the dataframe\n",
    "data.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- Spoiled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the schema of the dataframe\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|summary|                 A|                 B|                 C|                 D|            Spoiled|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|  count|               490|               490|               490|               490|                490|\n",
      "|   mean|  5.53469387755102| 5.504081632653061| 9.126530612244897| 5.579591836734694| 0.2857142857142857|\n",
      "| stddev|2.9515204234399057|2.8537966089662063|2.0555451971054275|2.8548369309982857|0.45221563164613465|\n",
      "|    min|                 1|                 1|               5.0|                 1|                0.0|\n",
      "|    max|                10|                10|              14.0|                10|                1.0|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'Spoiled']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assembling all the dependant features to a single vector column \"features\"\n",
    "assembler = VectorAssembler(inputCols=['A', 'B', 'C', 'D'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+---+-------+------------------+\n",
      "|  A|  B|   C|  D|Spoiled|          features|\n",
      "+---+---+----+---+-------+------------------+\n",
      "|  4|  2|12.0|  3|    1.0|[4.0,2.0,12.0,3.0]|\n",
      "|  5|  6|12.0|  7|    1.0|[5.0,6.0,12.0,7.0]|\n",
      "|  6|  2|13.0|  6|    1.0|[6.0,2.0,13.0,6.0]|\n",
      "+---+---+----+---+-------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a Random Forest Tree Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(labelCol='Spoiled', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = rfc.fit(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Random Forest Classifier Model, identifying the important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {0: 0.0202, 1: 0.0167, 2: 0.9428, 3: 0.0204})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__From the above observation, Feature at index 2 (Chemical C) is by far the most important feature, meaning it is causing the early spoilage!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
